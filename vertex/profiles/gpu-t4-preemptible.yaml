# Reusable Vertex AI custom training profile: gpu-t4-preemptible
# Single T4 GPU on Spot (preemptible) VMs with basic retry behavior.

# Use pipeline service account for proper API scopes/permissions
serviceAccount: sa-pipeline@plotpointe.iam.gserviceaccount.com

workerPoolSpecs:
- machineSpec:
    machineType: n1-standard-8
    acceleratorType: NVIDIA_TESLA_T4
    acceleratorCount: 1
  replicaCount: 1
  containerSpec:
    # PyTorch DLC image suitable for T4 (CUDA 12.1)
    imageUri: us-docker.pkg.dev/deeplearning-platform-release/gcr.io/pytorch-cu121.2-1.py310
    # Provide your command/args. Example echoes environment then runs your trainer.
    command: ["bash", "-lc"]
    args:
      - |
        set -e
        echo "Python: $(python -V 2>&1)"
        echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
        nvidia-smi || true
        python -m pip install --quiet --no-cache-dir google-cloud-aiplatform
        python - <<'PY'
        import os, time
        from datetime import datetime
        from google.cloud import aiplatform
        import torch

        PROJECT="plotpointe"
        LOCATION="us-central1"
        EXPERIMENT="recsys-dev"
        run_name=f"gpu-smoke-t4-preemptible-{int(time.time())}"

        print("torch:", torch.__version__, "cuda available:", torch.cuda.is_available())
        if not torch.cuda.is_available():
            raise SystemExit("CUDA not available")
        device = torch.device("cuda:0")
        name = torch.cuda.get_device_name(0)
        start = time.perf_counter()
        a = torch.randn(2048, 2048, device=device)
        b = torch.randn(2048, 2048, device=device)
        c = torch.mm(a, b)
        torch.cuda.synchronize()
        elapsed = time.perf_counter() - start
        print(f"DEVICE={name}")
        print(f"ELAPSED_SEC={elapsed:.4f}")

        aiplatform.init(project=PROJECT, location=LOCATION, experiment=EXPERIMENT)
        with aiplatform.start_run(run=run_name) as run:
            aiplatform.log_params({"profile":"gpu-t4-preemptible","device":name})
            aiplatform.log_metrics({"cuda_ok": 1.0, "elapsed_sec": elapsed})
        PY

scheduling:
  strategy: SPOT  # Use Spot (preemptible) VMs
  # restartJobOnWorkerRestart is recommended so the job auto-retries on preemptions.
  restartJobOnWorkerRestart: true

