# Vertex AI CustomJob config: GPU smoke test on T4
workerPoolSpecs:
- machineSpec:
    machineType: n1-standard-8
    acceleratorType: NVIDIA_TESLA_T4
    acceleratorCount: 1
  replicaCount: 1
  containerSpec:
    imageUri: us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.2-3:latest
    command: ["bash", "-lc"]
    args:
      - |
        set -e
        echo "Python: $(python -V 2>&1)"
        echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
        nvidia-smi || true
        python - <<'PY'
        import torch, time
        print("torch:", torch.__version__, "cuda available:", torch.cuda.is_available())
        if not torch.cuda.is_available():
            raise SystemExit("CUDA not available")
        device = torch.device("cuda:0")
        name = torch.cuda.get_device_name(0)
        start = time.perf_counter()
        a = torch.randn(2048, 2048, device=device)
        b = torch.randn(2048, 2048, device=device)
        c = torch.mm(a, b)
        torch.cuda.synchronize()
        elapsed = time.perf_counter() - start
        print(f"DEVICE={name}")
        print(f"ELAPSED_SEC={elapsed:.4f}")
        PY

